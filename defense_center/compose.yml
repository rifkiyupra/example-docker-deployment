# language: yaml
# yaml-language-server: $schema=https://raw.githubusercontent.com/compose-spec/compose-spec/master/schema/compose-spec.json
name: mataelang

volumes:
  kafka_data:
  opensearch_data1:

services:
  sensor-api:
    image: ghcr.io/mata-elang-stable/sensor-snort-service:latest
    command: "server -v"
    restart: unless-stopped
    depends_on:
      - broker
      - schema-registry
    ports:
      - "50051:50051"
    environment:
      - MES_SERVER_HOST=0.0.0.0
      - MES_SERVER_PORT=50051
      - MES_SERVER_INSECURE=true
      - MES_SERVER_MAX_MESSAGE_SIZE=1024
      - MES_SERVER_KAFKA_BROKERS=broker:29092
      - MES_SERVER_SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - MES_SERVER_KAFKA_GROUP_ID=sensor-api
      - MES_SERVER_KAFKA_TOPIC=sensor_events
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 512M

  broker:
    image: confluentinc/cp-kafka:7.8.0
    restart: unless-stopped
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_MESSAGE_MAX_BYTES=1073741824
      - KAFKA_JMX_PORT=9101
      - KAFKA_JMX_HOSTNAME=localhost
      - KAFKA_JMX_OPTS=-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka0 -Dcom.sun.management.jmxremote.rmi.port=9101
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@broker:29093
      - KAFKA_LISTENERS=PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LOG_DIRS=/tmp/kraft-combined-logs
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      - CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - kafka_data:/var/lib/kafka/data

  schema-registry:
    image: confluentinc/cp-schema-registry:7.8.0
    restart: unless-stopped
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=broker:29092
      - SCHEMA_REGISTRY_LISTENERS=http://0.0.0.0:8081

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    restart: unless-stopped
    depends_on:
      - broker
      - schema-registry
    ports:
      - "9021:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=MataElangKafkaCluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=broker:29092
      - KAFKA_CLUSTERS_0_SCHEMAREGISTRY=http://schema-registry:8081
      - KAFKA_CLUSTERS_0_METRICS_PORT=9101
      - DYNAMIC_CONFIG_ENABLED=true
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G

  event-stream-aggr:
    image: ghcr.io/mata-elang-stable/event-stream-aggr:latest
    restart: unless-stopped
    command: "-v"
    depends_on:
      - broker
      - schema-registry
    environment:
      - KAFKA_BROKERS=broker:29092
      - INPUT_KAFKA_TOPIC=sensor_events
      - OUTPUT_KAFKA_TOPIC=snort_alerts
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 512M

  opensearch-node1:
    image: opensearchproject/opensearch:2
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g
      - node.name=opensearch-node1
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD:-SecurePassword@123}
    env_file:
      - .env
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch_data1:/usr/share/opensearch/data

  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2
    restart: unless-stopped
    depends_on:
      - opensearch-node1
    ports:
      - 5601:5601
    environment:
      - OPENSEARCH_HOSTS=["https://opensearch-node1:9200"]
      - OPENSEARCH_DASHBOARDS_JAVA_OPTS=-Xms1g -Xmx1g
    env_file:
      - .env

  opensearch-logstash:
    image: opensearchproject/logstash-oss-with-opensearch-output-plugin:8.9.0
    restart: unless-stopped
    depends_on:
      - broker
      - schema-registry
      - opensearch-node1
      - opensearch-init
    command: "-f /usr/share/logstash/config/pipeline.conf"
    volumes:
      - ./conf/pipeline.conf:/usr/share/logstash/config/pipeline.conf:ro
    environment:
      - LS_JAVA_OPT=-Xmx512m -Xms512m
      - LOGSTASH_INTERNAL_PASSWORD=${LOGSTASH_INTERNAL_PASSWORD:-}
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD:-SecurePassword@123}
    env_file:
      - .env
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G

  opensearch-init:
    image: curlimages/curl:8.10.1
    restart: on-failure
    depends_on:
      - opensearch-node1
      - opensearch-dashboards
    command:
      - "/bin/sh"
      - "-c"
      - "/usr/local/bin/opensearch-init.sh"
    environment:
      - OPENSEARCH_URL=https://opensearch-node1:9200
      - DASHBOARDS_URL=http://opensearch-dashboards:5601
      - OPENSEARCH_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD:-SecurePassword@123}
    env_file:
      - .env
    volumes:
      - ./scripts/opensearch-init.sh:/usr/local/bin/opensearch-init.sh:ro
      - ./templates:/templates:ro
